{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "AutoEncoderStarter.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaschinenNah/MachineLearningKursCdV/blob/main/AutoEncoderStarter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTgyJI7L8MPo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "1fdd4c35-9c17-46b1-a528-cdfd1d7b0381"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "\n",
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0a741b3c1fa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPUClusterResolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'grpc://'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'COLAB_TPU_ADDR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_connect_to_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'COLAB_TPU_ADDR'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXkvqwKj8Fq1"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam\n",
        "from keras.datasets import mnist\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "N_PARAMS = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esUEHsiG8Fq8"
      },
      "source": [
        "encoder_input = Input(shape=(28,28,1))\n",
        "\n",
        "x = Conv2D(filters = 32, \n",
        "           kernel_size = (3,3), \n",
        "           strides = 1, \n",
        "           padding = 'same')(encoder_input)\n",
        "x = LeakyReLU()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(rate = 0.25)(x)\n",
        "\n",
        "x = Conv2D(filters = 64, \n",
        "           kernel_size = (3,3), \n",
        "           strides = 2, \n",
        "           padding = 'same')(x)\n",
        "x = LeakyReLU()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(rate = 0.25)(x)\n",
        "\n",
        "x = Conv2D(filters = 64, \n",
        "           kernel_size = (3,3), \n",
        "           strides = 2, \n",
        "           padding = 'same')(x)\n",
        "x = LeakyReLU()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(rate = 0.25)(x)\n",
        "\n",
        "x = Conv2D(filters = 64, \n",
        "           kernel_size = (3,3), \n",
        "           strides = 1, \n",
        "           padding = 'same')(x)\n",
        "x = LeakyReLU()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(rate = 0.25)(x)\n",
        "\n",
        "shape_before_flatten = K.int_shape(x)[1:]  \n",
        "\n",
        "x = Flatten()(x)\n",
        "encoder_output = Dense(N_PARAMS)(x)\n",
        "\n",
        "encoder = Model(encoder_input, encoder_output)\n",
        "\n",
        "encoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW5voASf8FrF"
      },
      "source": [
        "decoder_input = Input((N_PARAMS,))\n",
        "\n",
        "x = Dense(np.prod(shape_before_flatten))(decoder_input)\n",
        "x = Reshape(shape_before_flatten)(x)\n",
        "\n",
        "x = Conv2DTranspose(filters = 64, \n",
        "                    kernel_size = (3, 3), \n",
        "                    strides = 1, \n",
        "                    padding = 'same')(x)\n",
        "x = LeakyReLU()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(rate = 0.25)(x)\n",
        "\n",
        "x = Conv2DTranspose(filters = 64, \n",
        "                    kernel_size = (3, 3), \n",
        "                    strides = 2, \n",
        "                    padding = 'same')(x)\n",
        "x = LeakyReLU()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(rate = 0.25)(x)\n",
        "\n",
        "x = Conv2DTranspose(filters = 32, \n",
        "                    kernel_size = (3, 3), \n",
        "                    strides = 2, \n",
        "                    padding = 'same')(x)\n",
        "x = LeakyReLU()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(rate = 0.25)(x)\n",
        "\n",
        "x = Conv2DTranspose(filters = 1, \n",
        "                    kernel_size = (3, 3), \n",
        "                    strides = 1, \n",
        "                    padding = 'same')(x)\n",
        "x = Activation('sigmoid')(x)\n",
        "\n",
        "decoder_output = x\n",
        "\n",
        "decoder = Model(decoder_input, decoder_output)\n",
        "\n",
        "decoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0muBSXy8FrK"
      },
      "source": [
        "model_input = encoder_input\n",
        "model_output = decoder(encoder_output)\n",
        "model = Model(model_input, model_output)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XsrTD7U8FrP"
      },
      "source": [
        "optimizer = Adam(lr=0.0005)\n",
        "\n",
        "def r_loss(y_true, y_pred):\n",
        "    return K.mean(K.square(y_true - y_pred), axis = [1,2,3])\n",
        "\n",
        "\n",
        "\n",
        "model.compile(loss=r_loss, optimizer=optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBfdLc3A8FrV"
      },
      "source": [
        "model.fit(x_train[:2000], \n",
        "          x_train[:2000],\n",
        "          batch_size = 64,\n",
        "          shuffle = True,\n",
        "          epochs = 20,\n",
        "          validation_data = (x_test[:2000], x_test[:2000]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdH4lEG78Fra"
      },
      "source": [
        "model.evaluate(x_test, x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTInk_bm8Fre"
      },
      "source": [
        "n_to_show = 10\n",
        "example_idx = np.random.choice(range(len(x_test)), n_to_show)\n",
        "example_images = x_test[example_idx]\n",
        "\n",
        "z_points = encoder.predict(example_images)\n",
        "#print(z_points)\n",
        "\n",
        "reconst_images = decoder.predict(z_points)\n",
        "\n",
        "fig = plt.figure(figsize=(15, 3))\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "for i in range(n_to_show):\n",
        "    img = example_images[i].squeeze()\n",
        "    ax = fig.add_subplot(2, n_to_show, i+1)\n",
        "    ax.axis('off')\n",
        "    #ax.text(0.5, -0.35, str(np.round(z_points[i],1)), fontsize=10, ha='center', transform=ax.transAxes)   \n",
        "    ax.imshow(img, cmap='gray_r')\n",
        "\n",
        "for i in range(n_to_show):\n",
        "    img = reconst_images[i].squeeze()\n",
        "    ax = fig.add_subplot(2, n_to_show, i+n_to_show+1)\n",
        "    ax.axis('off')\n",
        "    ax.imshow(img, cmap='gray_r')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}